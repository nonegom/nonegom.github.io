---
title:  "[특강] - Artifical Intelligence(AI) 입문"
excerpt: "포스텍 Artifical Intelligence(AI) 입문 특강"
categories:
  - Special Lecture
tags:
  - 12월
og_image: "/assets/images/green.jpg"
toc: true
toc_sticky: true
toc_label: 페이지 목차
use_math: true
---

## AI특강

> 해당 강의는 포스텍에서 제공하는 'AI특강'에 대한 정리입니다.

- AI는 딥러닝의 발전으로 '인식'부분에 대해서는 사람과 유사할 정도로 올라왔다.

- 언어 분석에 중 하나인 Sentiment analysis 분야도 발달했다.

- Machine Translations(기계 번역) 부분도 아직 부족하지만, 많이 발달했다. 언어 데이터 처리 문제의 경우 인공지능 분야에서도 어려운 부분이다.

- 인공지능은 기계한테 이성적인 판단을 할 수 있게 알고리즘을 입력해주는 것일 뿐, 본능이나 감정을 이식하는 것은 아니다. 항간에서 일컫는 인공지능이 인간을 정복한다는 등의 디스토피아적 세계는 아직 멀다.

- AI라는 용어가 나온 이후 3번의 암흑기가 있었지만, 지금은 가장 눈부신 황금기를 누리고 있다고 할 수 있다.

- 실생활에 가장 가깝게 다가와 있는 부분으로 Virtua Assistants(알렉사, 시리, 구글)들이 있다. (영어는 잘 인식하지만, 한국말은 아직 부족하긴 하다)

### Dialog System
- '2016 ten breakthrough technology from MIT technology review'에 뽑힐만큼 유망있는 기술로 뽑혔다.
- Chat bot, Tutor robot, ...

- 현재 많은 자동차 회사들이 이러한 Dialog System을 이용할 수 있게 연구를 진행하고 있다. 

### Two Sources of complexity
- AI는 다양한 부분에 응용할 수 있는데 크게 **두 가지의 complexity(복잡성)**가 있다.

- Computational Complexity: 최적의 솔루션이 있는 문제
  - 알파고가 활약한 바둑의 경우도, 최적의 수가 있는 문제였지만 $361^{200}$개의 문제가 있었다.
- Information Complexity: 문장을 번역하거나, 이미지를 분석하는 것

### Exapmle of AI 

1. **AlphaGo**: 30million training data / Tensor Processing Unit, Deep & Reinforcement Learinng 활용
2. **NVIDIA Auto Driving**: Vision data(driving tens of thousands miles) / NVIDIA GPU, Deep Learning
3. **Google Translation**: Billions of translation data

> AI를 제대로 사용하기 위해서는 BigData + Hardware + MachineLearning Algorithm 이 세 가지가 필요하다.

### AI task process
**Real-world task** -(modeling)-> **Formal task(model)** -(Algorithms)-> **program**

- Modeling and Algorithms
  - Separate what to compute(modeling) from how to compute it(algorithms) -> Advantage: division of labor

### What do we learn?
- Type of models...
- Art of modeling...
- Developing Algorithms...

## 4가지 모델

### Reflex-based Models
**Low-level intelligence**

- Sentiment Analysis
  - Simple examples: model $f$ is a set of simple rules (긍정적 단어있으면 Positive, 부정적 단어있으면 Negative)
  - Next examples: $f$ is based on scores (긍정의 단어 있으면 score +=, 부정의 단어가 있으면 -=)
  
- 이를 수학적으로 $f(x) = sign (w_1 \phi_1 + 1(x) + \cdots + w_d\phi_d(x))$로 표현할 수 있다.
- 위와 같은 폼을 **linear classifier**라고 한다.

> linear classifier는 많은 '뉴럴네트워크 딥러닝'에도 사용되고 있다.  

- Sentiment Analysis에서는 'training'을 시키기 위해서 Label이 필요하다.
    - Label은 사람이 긍정인지, 부정인지를 확인해서 만들어줘야 한다.

### 성능 판단 방법
- Key Idea: Generalization
    - How to generalize from training to test?

- training했던 데이터로 test를 실시한다면 이런 경우 overfitting 등의 문제가 나올 수 있다. 
- 따라서 train에 사용되지 않았던 데이터로 test를 하면서 성능을 확인해야 한다. 즉, generailzation 성능을 올릴 수 있게 신경써야 한다.

### States-based Models
**Search problems, Markov Decision proces**

- Text Reconstruction
  - 중국어는 띄어쓰기가 없거나, 아랍어에는 모음이 없는 경우도 있다. 

- Solutions are represented as paths through a graph
- Key idea: state
  - A state captures all the relevant information about the past in order to act optimally in the future
  - 최적의 방법, 이길 수 있는 방법을 찾는 알고리즘 (알파고에 사용된 것과 유사)

### Variables-based Models 
**Constraint satisfaction problems, Baysian networks**

- Constraint Satisfaction problem(CSP)
Q> 3가지 색을 사용해서, 7개의 인접한 블록을 칠해야 한다. 하지만 같은 색의 경우 연달아 사용하지 않을 때 색을 칠할 수 있는 방법

- Event Scheduling

- 특정한 조건이 있는 경우, 이 조건들을 만족시키는 방법을 찾는 모델

- 위와 같은 모델들을 확률적으로 추측하는데 사용하는 경우가 'Baysian Networks(히든 마코프 모델(HVM)))'이다. 

### Logic

- Question-Answer
  - Logic의 문제는 최근에는 이러한 문제는 Deep Learning과 관련돼서 대체 되는 경우가 많다.

## Summary so far
- Applications of AI: high-impact, diverse
- Challenges: Computational/information complexity
- Paradigm: modeling + algorithms
- Models: Learning + [reflex, states, variables, logic]

## Types of prediiction tasks
- Binary classification
- Regression
- Multiclass classification
- Ranking: y is a permutation
- Structured prediction

> Framework는 동일하다. train데이터를 특정 Algorithm으로 학습해서 문제를 해결한다. 

### Optimization

- 머신러닝의 문제는 특정한 $w$값을 찾는 optimization을문제로 귀결된다. 

- Models are optimization problems:
$$\underset{x \in C}min F(x)$$

## Features
- 딥러닝이 나오기 전에는 사람이 Feature를 정의해줘야 했다. 하지만 딥러닝의 발달로 머신러닝의 성능이 무척 올라갔다. 

- Feature exraction
  - Feature extractor: Given input $x$, output a set of(feature name, feature values)
  - Mathmatically, **feature vector** doesn't need feature names
  - 이러한 feature 기준을 사람들이 찾아서 입력해준다.
  - 그렇다면 머신러닝은 이러한 feature 기준으로 최적의 $w$를 찾는다.

- Hypothesis class
  - A hypothesis class is the set of possible predictors with a fixed $\phi(x)$ and varying $w$.

> 좋은 성능의 모델링을 하기 위해서는 feature를 잘 define해야 한다.

## Generalization
- 어떻게 일반화(Generalization)를 잘 할 수 있을 것인가?

### Overfitting
- 모델이 training 데이터에만 최대한 맞추려고 과최적화 되는 경우이다.

### Evaluation
- How good is the predictor $f$?
    - Our goal is to minimize error on unseen future examples

### Hyperparameters
- properties of the learning algorithm

### Validation
- A **validation set** is taken out of the training data which acts as a surrogate for the test set (30% data)

> 사실 정확한 generalization값을 추정하는 것보다는 하이퍼파라미터($w$)를 찾는 게 더 중요하다.


## Machine Learning Summary
- **Modeling $f$ => Optimization**: design loss well to reflect what you really want
- **Features**: Design features well to reduce data
- **Generalization**: regularize well to generalize