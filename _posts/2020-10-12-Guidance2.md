---
title:  "머신러닝(지도학습) - 1.2.분류용 가상 데이터"
excerpt: "파이썬에서 '분류모형'을 테스트하기 위한 가상데이터 생성 함수의 종류"

categories:
  - MachinLearning
tags:
  - Guidance&Studying
  - 10월
toc: true
toc_sticky: true
toc_label: 페이지 목차

---
> 아래 포스팅은 기존 수업의 복습 차원에서 올리는 포스팅입니다. 좀 더 구체적인 자료를 원하시면 [데이터 사이언스 사이트](https://datascienceschool.net/03%20machine%20learning/09.02%20%EB%B6%84%EB%A5%98%EC%9A%A9%20%EA%B0%80%EC%83%81%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%83%9D%EC%84%B1.html) 참고 부탁드립니다. 특히 아래 코드의 plt 그래프의 모습을 보고 싶으시면 확인부탁드립니다.

## 0. 분류용 가상 데이터 생성
 '사이킷런 패키지'에서는 '분류(classification)모형'의 테스트 를 위해 여러가지 가상 데이터를 생성하는 함수를 제공한다.


## 1. make_classification
 설정에 따른 분류용 가상 데이터를 생성하는 명령. 
 - 인수 (일부)
    - n_samples : 표본 데이터의 수
    - n_features : 독립 변수의 수
    - n_informative : 독립 변수 중 종속 변수와 상관 관계가 있는 성분의 수
    - n_redundant : 독립 변수 중 다른 독립 변수의 선형 조합으로 나타나는 성분의 수
    - n_repeated : 독립 변수 중 단순 중복된 성분의 수
    - weights: 각 클래스에 할당된 표본 수(가중치)
    - random_sates: 난수 발생 시드

- 반환값
    - X: [n_samples, n_features] 크기의 배열 / **독립변수**
    - y: [ n_samples ] 크기의 배열 / **종속변수**


### 1) 1개의 독립변수를 가지고, 2개의 클래스를 가지는 데이터 생성
---

```python
from sklearn.datasets import make_classification
X, y = make_classification(n_features=1, n_informative=1,
  n_redundant=0, n_clusters_per_class=1, random_state=4)
```


### 2) 2개의 독립변수를 가지고, 2개의 클래스를 가지는 데이터 생성
---
#### - n_informative 변수를 1로 설정. 
즉, 2개의 독립변수 중 실제로 타겟 클래스와 상관관계가 있는 독립변수는 1개뿐이다.

```python
from sklearn.datasets import make_classification
X, y = make_classification(n_features=2, n_informative=1,
  n_redundant=0, n_clusters_per_class=1, random_state=4)
```

#### - n_informative 변수를 2로 설정
이 경우, 두 변수 모드 클래스와 상관관계가 있는 가상 데이터가 생성된다.

```python
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=500, n_features=2, n_informative=2,
  n_redundant=0, n_clusters_per_class=1, random_state=6)
```


### 3) 클래스 별 데이터 갯수의 차이가 있는 데이터 생성
---
weight인수 설정을 통해 클래스별로 가중치를 줄 수 잇다. 아래의 코드에서는 weight 인수를 각각 0.9와 0.1로 설정했다. 이럴 경우 앞 클래스가 뒤의 클래스보다 9배 더 많이 나오게 된다. 

```python
plt.title("비대칭 데이터")
X, y = make_classification(n_features=2, n_informative=2, n_redundant=0,
n_clusters_per_class=1, weights=[0.9, 0.1], random_state=6)
```

### 4) 클래스끼리 잘 분리되어 있지 않은 가상데이터 생성
---
n_clusters_per_class 인수를 2로 설정하여, 클래스 당 클러스터 갯수를 늘리면 클래스끼리 잘 분리되어 있지 않은 가상데이터를 얻을 수 있다.

``` python
X, y = make_classification(n_samples=400, n_features=2, n_informative=2, 
n_redundant=0, n_clusters_per_class=2, random_state=0)
```

### 5) 다중 클래스를 가지는 가상데이터 생성
---
```python
X, y = make_classification(n_samples=300, n_features=2, n_informative=2, 
n_redundant=0, n_clusters_per_class=1, n_classes=3, random_state=0)
```

## 2. make_blobs
**등방성 가우시안 정규분포**를 이용해 가상 데이터 생성한다. **등방성**이라는 말은 모든 방향으로 같은 성질을 가진다는 뜻이다. `make_blobs`는 보통 클러스터링용 가상데이터를 생성하는데 사용한다. 이를 이용해 분류용 샘플 모형을 만들 수 있다.
- 인수
  - n_samples: 표본 데이터의 수
  - n_features: 독립 변수의 수
  - centers: 생성할 클러스터의 수 혹은 중심, [n_centers, n_feature] 크기의 배열
  - cluster_std: 클러스터의 표준 편차
  - center_box: 생성할 클러스터의 바운딩 박스

- 반환값
    - X: [n_samples, n_features] 크기의 배열 / **독립변수**
    - y: [ n_samples ] 크기의 배열 / **종속변수**

## 3. make_moons
**초승달 모양 클러스터 두 개 형상**의 데이터를 생성. `make_moons`명령으로 만든 데이터는 직선을 사용해 분류할 수 없다.
- 인수:
  - n_samples : 표본 데이터의 수, 디폴트 100
  - noise : 잡음의 크기. 0이면 정확한 반원을 이룸

  ```python
  X, y = make_moons(n_samples=400, noise=0.1, random_state=0)
  ```

## 4. make_gaussian_quantiles
**다차원 가우시안 분포**의 표본을 생성하고 분포의 기대값을 중심으로 한 등고선으로 클래스를 분리한다. 이 데이터는 타원형 형태의 닫힌 경계선으로만 분류할 수 있다.

- 인수:
  - mean : 기댓값 벡터
  - cov : 공분산 행렬
  - n_samples : 표본 데이터의 수, 디폴트 100
  - n_features : 독립 변수의 수, 디폴트 20
  - n_classes : 클래스의 수

- 반환값:
  - X : [n_samples, n_features] 크기의 배열 / **독립변수**
  - y : [n_samples] 크기의 배열 / **종속변수**

```python
X, y = make_gaussian_quantiles(n_samples=400, n_features=2, 
n_classes=2, random_state=0)
```