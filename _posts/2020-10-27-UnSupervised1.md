---
title:  "[머신러닝] 비지도학습 - 1. 군집화"
excerpt: "비지도학습 중 군집화에 관한 OverView 및 성능기준"

categories:
  - ML_Unsrpervised
tags:
  - UnSupervisedLearning
  - 10월
toc: true
toc_sticky: true
toc_label: 페이지 목차
use_math: true
---
> 아래 포스팅은 기존 수업의 복습 차원에서 올리는 포스팅입니다. 따라서 세부적인 수학적 정리가 생략된 부분이 있습니다. 따라서 좀 더 구체적인 정보나 원하시면 [데이터 사이언스 스쿨 사이트](https://datascienceschool.net/03%20machine%20learning/16.01%20%EA%B5%B0%EC%A7%91%ED%99%94.html)를 참고 부탁드립니다. 특히 아래 코드를 이용한 시각화 그래프 코드와 모습을 보고 싶으시면 링크 확인부탁드립니다.  

## 비지도학습
 **종속데이터 y가 없이 순수 데이터**만 있는 경우에 모델을 학습시키기 위한 방법

## 0. 군집화
 주어진 데이터 집합을 유사한 데이터들의 그룹으로 나누는 것을 군집화(Clustering)라고 한다. 군집화는 예측문제와 달리 **특정한 독립변수와 종속변수의 구분도 없고** 학습을 위한 **목푯값도 필요로 하지 않는 **비지도학습**의 일종이다.

### 군집화 방법

- K-평균 군집화(K-means Clustering)
- 디비스캔 군집화(DBSCAN Clustering)
- 유사도 전파 군집화(Affinity Propagation Clustering)
- 계층적 군집화(Hierarchical Clustering)
- 스펙트럴 군집화(Spectral Clustering)

군집화 방법은 사용법과 모수 등이 서로 다르다. 예를 들어 K-평균법이나 스펙트럴 군집화 등은 군집의 개수를 미리 지정해주어야 한다. 하지만 디비스캔이나 유사도 전파법 등은 군집의 개수를 지정할 필요가 없지만, 모형에 따라 특별한 모수를 지정해줘야 한다. 그리고 이 모수 값에 따라 군집화 개수가 달라질 수가 있다.
- 각 군집화 방법마다 특성이 다르므로 **원하는 목적과 데이터 유형**에 맞게 사용해야 한다. 또한 지정된 **모수의 값에 따라 성능**이 달라질 수 있다. 

> 군집화 방법이 가지고 있는 개별 특징을 이해하고, 필요할 때 사용할 수 있을 정도의 지식을 갖고 있으면 된다.


![](/assets/images/UnSupervised1_1.png)

- K- Means의 경우 가장 많이 쓰이는 단순한 방법이다.
- DBSCAN의 경우 대부분 잘되나 **비구조화 데이터**의 경우 잘 안된다. 
- 고급 알고리즘으로 갈 수록 조금 더 분류가 잘 되는 것을 확인할 수 있다.
- Spectral Clustering의 경우 복잡한 알고리즘이 들어가 있지만, 분류가 제일 잘 된다. 


## 1. 군집화 성능기준
군집화의 경우 분류문제와는 다르게 성능기준을 만들기 어렵기 때문에, 성능을 따질 수 있는 다양한 **성능기준**이 사용된다. 라벨링이 되어 있는 경우가 있고, 라벨링이 되어있지 않은 경우를 구분해 사용한다.

- 조정 랜드지수(Adjusted Rand Index)
- 조정 상호정보량 (Adjusted Mutual Information)
- 실루엣계수 (Silhouette Coefficient) 
    - 라벨링이 되어있지 않은 상태에서 대강 추측가능 - 간단한 클러스터에서는 동작하지만, 복잡한 클러스터에서는 동작하지 않는다.

### 일치행렬
라벨링이 되어있다는 것은 어떠 클래스들이 같은 클래스이고, 어떤 클래스들이 다른 데이터들인지 구분되어 있다는 것이다.

1. **두 개의 데이터**를 선택하였을 때, 그 두 데이터가 같은 군집에 속하면 1 다른 군집에 속하면 0이라고 하자. 이 값을 $N x N$ 행렬 $T$로 나타내면 **군집**이 나눠진다.
2. 이제 **군집화 결과**를 행렬 $C$로 표시한다. 만약 군집화가 정확하다면 이 행렬은 정답을 이용해서 만든 행렬과 거의 같은 값을 가져야 한다.
3. 이 두 행렬의 모든 원소에 대해 각 위치에서 값이 같으면 1 다르면 0으로 계산한 행렬을 만든다. 이 행렬을 **일치행렬(incidence matrix)**이라고 한다. 이 일치 행렬은 두 데이터의 순서를 포함하므로 **대칭행렬**이다.

```py
# 1. 두 개의 데이터의 군집 T
groundtruth = np.array([
    [1, 1, 1, 0, 0],
    [1, 1, 1, 0, 0],
    [1, 1, 1, 0, 0],
    [0, 0, 0, 1, 1],
    [0, 0, 0, 1, 1],
])

# 2. 군집화 결과 행렬 C
clustering = np.array([
    [1, 1, 0, 0, 0],
    [1, 1, 0, 0, 0],
    [0, 0, 1, 1, 1],
    [0, 0, 1, 1, 1],
    [0, 0, 1, 1, 1],
])

# 3. 일치행렬
incidence = 1 * (groundtruth == clustering) 
# 1을 곱하는 이유는 True & False를 1과 0으로 바꾸기 위함 
incidence
"""> 
array([[1, 1, 0, 1, 1],
       [1, 1, 0, 1, 1],
       [0, 0, 1, 0, 0],
       [1, 1, 0, 1, 1],
       [1, 1, 0, 1, 1]])
"""
```

만약 데이터의 순서를 무시한다면 위 행렬에서 대각성분과 아래쪽 비대각 성분은 제외한 **위쪽 비대각 성분만을 고려**해야 한다. 따라서 위쪽 비대각 성분에서의 1의 개수는 다음과 같다.
$$a = \text{T에서 같은 군집에 있고 C에서도 같은 군집에 있는 데이터 쌍의 수}$$
$$b = \text{T에서 다른 군집에 있고 C에서도 다른 군집에 있는 데이터 쌍의 수}$$
$$ \text{일치행렬 위쪽 비대각 성분에서 "1의 개수}  = a + b"$$

```py
np.fill_diagonal(incidence, 0)   # 대각성분 제외
a_plus_b = np.sum(incidence) / 2 # 대칭행렬이므로 절반만 센다.
a_plus_b

# sum으로 계산하는 이유는 "1의 개수"를 세기만 하면 되기 때문이다.
```

### 랜드지수 (Rand Index, RI)
가능한 모든 데이터 쌍의 개수에 대해 **정답인 데이터 쌍의 개수의 비율**로 정의
$$Rand \ Index = \frac {a+b} {_N C_2}$$
```py
# a_plus_b: 위에서 구한 일치행렬의 비대각 성분에서 1의 개수
from scipy.special import comb
rand_index = a_plus_b / comb(incidence.shape[0], 2)
rand_index
```

##  1) 조정 랜드지수 (ARI)
랜드지수는 0부터 1까지의 값을 가지고 1이 가장 좋은 성능을 뜻한다. 그러나 랜드지수의 문제점은 무작위로 군집화를 한 경우에도 어느 정도 좋은 값이 나올 가능성이 높다는 점이 있다는 문제점이 있다.
- 따라서 원래의 기대값에서 **무작위 군집화에서 생기는 랜드지수의 기댓값**을  빼서 **기댓값과 분산을 재조정**한 것이 **조정 랜드지수(Adjusted Rand Index, ARI)**이다.

조정 랜드지수의 결과로 성능이 완벽한 경우 1이 되고, 반대로 가장 나쁜 경우,무작위 군집화에 가까운 경우로, 0에 가까운 값이 나온다. 경우에 따라서는 음수가 나올 수도 있다.


`scikit-learn 패키지 metrics cluster 서브패키지`는 조정 랜드지수를 계산하는 `adjusted_rand_score`명령을 제공한다. (코드 생략) 조정 랜드지수를 계산해보면 디비스캔과 스펙트럴 군집화의 값이 높게 나오는 것을 확인할 수 있다.

![](/assets/images/UnSupervised1_2.JPG)
- ARI의 계수가 높을 수록 클래스 분류가 잘 되고 있음을 확인할 수 있다.

> 따라서 ARI라는 것을 통해 우리는 라벨링 되어있는 군집화의 성능을 측정할 수 있다.

##  2) 조정 상호정보량 (AMI)
corelation은 선형적인 상관관계를 측정가능한데, mutual information은 비선형적인 상관관계를 파악 가능하다. 즉, **상호정보량**(mutual information)은 **두 확률변수간의 상호 의존성**을 측정한 값이다.군집화 결과를 이산확률변수라고 가정한다. 

확률변수 $T, C$의 상호 정보량은 아래와 같이 정의 한다.
$$MI(T,C) = \sum_{i=1}^r\sum_{j=1}^sP(i, j)log \frac{P(i,j)}{P(i)P'(j)}$$ 

두 확률변수가 의존성이 강할수록 상호정보량은 증가한다. 또한 군집의 개수가 많아져도 상호정보량이 증가하므로 올바른 비교가 어렵다. 따라서 조정 랜드지수의 경우와 마찬가지로 각 경우에 따른 **상호정보량의 기댓값을 빼서** 재조정한 것이 **조정 상호정보량(Adjusted Mutual Information, AMI)**이다.  


`scikit-learn 패키지 metrics cluster 서브패키지`는 조정 랜드지수를 계산하는 `adjusted_mutual_info_score`명령을 제공한다. (코드 생략)디비스캔과 스펙트럴 군집화의 값이 높게 나오는 것을 확인할 수 있다.

![](/assets/images/UnSupervised1_3.JPG)
- AMI의 계수가 높을 수록 클래스 분류가 잘 되고 있음을 확인할 수 있다.

> 여기까지는 라벨링을 통해 클러스터링을 확인할 수 있었다.

##  3) 실루엣계수
지금까지는 각각의 데이터가 원래 어떤 군집에 속해있었는지 **정답(groundtruth)**를 알고 있는 경우를 다루었다. 하지만 이러한 정답 정보가 없다면 어떻게 군집화이 잘되었는지 판단할 수 있을까? **실루엣계수**(Silhouette coefficient)는 이러한 경우에 군집화의 성능을 판단하기 위한 기준의 하나이다.


우선 **모든 데이터 쌍**$(i, j)$에 대해 **거리 혹은 비유사도**(dissimilarity)를 구한다. 이 결과를 이용해 모든 데이터 $i$에 대해 다음 값을 구한다.
- $a_i$: $i$와 같은 군집에 속한 원소들의 평균 거리
- $b_i$: $i$와 다른 군집 중 가장 가까운 군집까지의 평균 거리
- 같은 편이라 얼마나 가까운가, 다른 편이랑 얼마나 가까운가? 를 구하는 것.

이때 데이터 $i$에 대한 실루엣 계수는 아래와 같다. 만약 클러스터링이 잘되었다면 내 편과의 거리는 가깝고, 다른 편과의 거리는 멀어질 것이다. 전체 데이터의 실루엣 계수가 평균된 값을 **평균 실루엣 계수**라고 한다.
$$s_i = \frac {b_i - a_i} {max(a_i, b_i)}$$

잘못된 군집화에서는 실루엣계수가 음수인 데이터가 많아지므로 평균 실루엣 계수가 작아진다. 따라서 실루엣계수가 클수록 좋은 군집화라고 할 수 있다.


군집화 방법 중 군집의 개수를 사용자가 정해주어야 할 경우가 있을 때, 실루엣 계수는 이에 큰 도움을 줄 수 있다. 군집의 개수를 여러 개 변경시켜 확인해 보면서 실루엣 계수의 평균이 높게 나오는 경우를 픽한다. (코드 생략)

![](/assets/images/UnSupervised1_4.png)
- 군집 수가 '3'개일 때 실루엣계수의 평균(coefficient)이 가장 높게 형성됨을 알 수 있다.
- 군집 수가 '2'개일 때 음수로 측정된 부분이 확인된다.
- 군집 수가 '4, 5'개일 때 split 현상이 발생한다.


> 실루엣계수는 군집의 형상이 복잡하거나 크기의 차이가 많이나면 정상적인 비교가 불가능하다.

![](/assets/images/UnSupervised1_5.png)
- 군집 수가 2개일 때 가장 분류가 잘 된 것으로 보이지만, 다른 경우보다 평균값(coefficient)이 낮게 나왔다.
- 따라서 실루엣 계수를 마냥 믿을 수 없기에, 보통은 라벨링을 통해 군집화의 성능을 측정하는 것이 가장 좋다. 

## 참고
- 라벨 데이터를 만드는 것은, 여러 개의 데이터에서 **라벨링할 수 있는 데이터만 뽑아서 라벨링을** 한다. 하지만 그러기 위해서는 모든 feature를 확인해야 한다. 만약 학습 데이터의 경우 100개의 데이터를 뽑았다면 그 데이터로 나와 컴퓨터 모두 같이 돌려본다. 그리고 조사한 샘플 데이터가 내 것과 컴퓨터의 결과가 같으면 그 샘플 데이터가 원래의 데이터에 대해서도 적용되겠다고 생각할 수 있다. 

- 라벨링을 했다고 지도학습이라고 할 수 없다. 성능 측정에 라벨이 필요한 것은 다른 범주이다. 학습할 시점에 라벨이 필요하냐, 필요하지 않냐가 지도학습, 비지도학습의 기준이다. 아무튼 군집화에서는 성능 측정에 있어 어려움이 존재한다.